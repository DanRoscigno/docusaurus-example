(window.webpackJsonp=window.webpackJsonp||[]).push([[12],{105:function(e,t,a){"use strict";a.d(t,"a",(function(){return b})),a.d(t,"b",(function(){return d}));var n=a(0),r=a.n(n);function i(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function s(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){i(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var c=r.a.createContext({}),p=function(e){var t=r.a.useContext(c),a=t;return e&&(a="function"==typeof e?e(t):s(s({},t),e)),a},b=function(e){var t=p(e.components);return r.a.createElement(c.Provider,{value:t},e.children)},m={inlineCode:"code",wrapper:function(e){var t=e.children;return r.a.createElement(r.a.Fragment,{},t)}},u=r.a.forwardRef((function(e,t){var a=e.components,n=e.mdxType,i=e.originalType,o=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),b=p(a),u=n,d=b["".concat(o,".").concat(u)]||b[u]||m[u]||i;return a?r.a.createElement(d,s(s({ref:t},c),{},{components:a})):r.a.createElement(d,s({ref:t},c))}));function d(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var i=a.length,o=new Array(i);o[0]=u;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:n,o[1]=s;for(var c=2;c<i;c++)o[c]=a[c];return r.a.createElement.apply(null,o)}return r.a.createElement.apply(null,a)}u.displayName="MDXCreateElement"},154:function(e,t,a){"use strict";a.r(t),t.default=a.p+"assets/images/streaming-pipeline-3317ae72baa2e1d90cdff31dbc40570f.png"},155:function(e,t,a){"use strict";a.r(t),t.default=a.p+"assets/images/data-f70a55c1863baab11d71bbeebc6d8fc7.png"},156:function(e,t,a){"use strict";a.r(t),t.default=a.p+"assets/images/tweets-example-477558aa69c626d1da0e40cb90c3ac56.png"},157:function(e,t,a){"use strict";a.r(t),t.default=a.p+"assets/images/image-example-c5ae9f8cb9ce63f0eec2a665db28c798.png"},80:function(e,t,a){"use strict";a.r(t),a.d(t,"frontMatter",(function(){return o})),a.d(t,"metadata",(function(){return s})),a.d(t,"toc",(function(){return l})),a.d(t,"default",(function(){return p}));var n=a(3),r=a(7),i=(a(0),a(105)),o={title:"Data Engineering Project - Intro - Part 1",author:"Kristijan Bakaric",author_title:"Mr.",author_url:"https://www.linkedin.com/in/kristijanb/",author_image_url:"https://media-exp1.licdn.com/dms/image/C4E03AQF-5oI5fHJPjw/profile-displayphoto-shrink_800_800/0/1606336983715?e=1620259200&v=beta&t=VvBP6s8IMDUwKDfvj6B3c-gGmN3IfioALIAboXg_DGE",tags:["dataengineering","projects","azure","python"],hide_table_of_contents:!1},s={permalink:"/personal-website/blog/2021/02/28/data-engineering-part1",source:"@site/blog/2021-02-28-data-engineering-part1.md",description:"The Main goal of this post is to introduce an Azure Data Engineering Project where I will prototype streaming and batch processing data pipelines, with the main purpose to ingest and process data that consists of tweets and satellite images extracted from Kaggle datasets.",date:"2021-02-28T00:00:00.000Z",tags:[{label:"dataengineering",permalink:"/personal-website/blog/tags/dataengineering"},{label:"projects",permalink:"/personal-website/blog/tags/projects"},{label:"azure",permalink:"/personal-website/blog/tags/azure"},{label:"python",permalink:"/personal-website/blog/tags/python"}],title:"Data Engineering Project - Intro - Part 1",readingTime:2.615,truncated:!0,prevItem:{title:"Data Engineering Project - Pre-process data - Part 2",permalink:"/personal-website/blog/2021/03/06/data-engineering-part2"},nextItem:{title:"Analysis of Seattle\u2019s Airbnb Data",permalink:"/personal-website/blog/2020/04/03/analysis-seattle-airbnb"}},l=[{value:"Introduction",id:"introduction",children:[]},{value:"Data",id:"data",children:[{value:"Hurricane Harvey Tweets",id:"hurricane-harvey-tweets",children:[]},{value:"Satellite Images of Hurricane Damage",id:"satellite-images-of-hurricane-damage",children:[]}]},{value:"In the Next Post...",id:"in-the-next-post",children:[]}],c={toc:l};function p(e){var t=e.components,o=Object(r.a)(e,["components"]);return Object(i.b)("wrapper",Object(n.a)({},c,o,{components:t,mdxType:"MDXLayout"}),Object(i.b)("p",null,Object(i.b)("img",{parentName:"p",src:"https://images.unsplash.com/photo-1584033844021-260872c289d2?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&ixlib=rb-1.2.1&auto=format&fit=crop&w=1950&q=80",alt:null})),Object(i.b)("blockquote",null,Object(i.b)("p",{parentName:"blockquote"},"The Main goal of this post is to introduce an Azure Data Engineering Project where I will prototype streaming and batch processing data pipelines, with the main purpose to ingest and process data that consists of tweets and satellite images extracted from Kaggle datasets.")),Object(i.b)("p",null,"Personal motivation for this project is to explore Azure in the light of data engineering and its service offerings."),Object(i.b)("h2",{id:"introduction"},"Introduction"),Object(i.b)("p",null,"The upcoming posts will consist of writing about:"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},"Python functions and modules that process the data from Kaggle, combine tweets and satelite images into a single file acting as a source of streaming data, and building a python program that will send requests to an Azure API endpoint. ")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},"Azure streaming data pipeline that:"),Object(i.b)("ul",{parentName:"li"},Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},"Ingests tweets from the local source client via Azure API management having an Azure Function as a backend.")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},"Utilizes Azure Event Hub as a message queue service.")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},"Azure Function that takes messages from Azure Event Hub and writes them to Azure Cosmos Database.")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("img",{src:a(154).default}))))),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},"Azure batch data pipeline that will take daily tweets in a form of csv reports, process them and store them to the same serving data store, Azure Cosmos Database.")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},"Python Streamlit Web App (acting as a prototype) that sources data from Cosmos DB, and visualises it in a set of insightful charts. It will be deployed on Azure Web App Service. "))),Object(i.b)("h2",{id:"data"},"Data"),Object(i.b)("p",null,Object(i.b)("img",{src:a(155).default})),Object(i.b)("p",null,"Data for the project consists of:"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",{parentName:"li",href:"https://www.kaggle.com/dan195/hurricaneharvey"},"Hurricane Harvey Tweets")," from Kaggle."),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",{parentName:"li",href:"https://www.kaggle.com/kmader/satellite-images-of-hurricane-damage"},"Satellite Images of Hurricane Damage")," from Kaggle")),Object(i.b)("div",{className:"admonition admonition-note alert alert--secondary"},Object(i.b)("div",{parentName:"div",className:"admonition-heading"},Object(i.b)("h5",{parentName:"div"},Object(i.b)("span",{parentName:"h5",className:"admonition-icon"},Object(i.b)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},Object(i.b)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"}))),"note")),Object(i.b)("div",{parentName:"div",className:"admonition-content"},Object(i.b)("p",{parentName:"div"}," Since there is no apparent real relation in the data between tweets and satelite images, for this project, I decided to mock the relation and randomly assign ids from images to tweets to create an artificial relationship."))),Object(i.b)("h3",{id:"hurricane-harvey-tweets"},"Hurricane Harvey Tweets"),Object(i.b)("p",null,"Tweets containing Hurricane Harvey which spans from morning of 8/25/2017 to 8/30, as well as the properly merged version of the dataset including Tweets from when Harvey before it was downgraded back to a tropical storm."),Object(i.b)("p",null,"The dataset has 7 columns, of which the first is just the index. The rest are as follows..."),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"ID")," - Twitter ID")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"Time")," - Datetime stamp of tweet")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"Tweet")," - Text content of tweet")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"Retweets")," - Number of retweers")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"Replies")," Number of replies to a given tweet")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("p",{parentName:"li"},Object(i.b)("strong",{parentName:"p"},"Likes")," Number of likes of a given tweet"))),Object(i.b)("p",null,"Example of the table:\n",Object(i.b)("img",{src:a(156).default})),Object(i.b)("h3",{id:"satellite-images-of-hurricane-damage"},"Satellite Images of Hurricane Damage"),Object(i.b)("p",null,"The data are satellite images from Texas after Hurricane Harvey divided into two groups (damage and no_damage). "),Object(i.b)("p",null,"Source: Data is originally taken from: ",Object(i.b)("a",{parentName:"p",href:"https://ieee-dataport.org/open-access/detecting-damaged-buildings-post-hurricane-satellite-imagery-based-customized"},"https://ieee-dataport.org/open-access/detecting-damaged-buildings-post-hurricane-satellite-imagery-based-customized")," and can be cited with ",Object(i.b)("a",{parentName:"p",href:"http://dx.doi.org/10.21227/sdad-1e56"},"http://dx.doi.org/10.21227/sdad-1e56")," and the original paper is here: ",Object(i.b)("a",{parentName:"p",href:"https://arxiv.org/abs/1807.01688"},"https://arxiv.org/abs/1807.01688")),Object(i.b)("p",null,"Example of an image, and the directories together with the image files:\n",Object(i.b)("img",{src:a(157).default})),Object(i.b)("h2",{id:"in-the-next-post"},"In the Next Post..."),Object(i.b)("p",null,"In the next post, I will introduce Python functions and modules that process the data from Kaggle, combine tweets and satellite images into a single json file acting as a source of streaming data, and building a python program that will send requests to an Azure API endpoint, where each request will be a single tweet with a predefined schema. "))}p.isMDXComponent=!0}}]);