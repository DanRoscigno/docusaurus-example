<!doctype html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-alpha.fd17476c3">
<link rel="alternate" type="application/rss+xml" href="/personal-website/blog/rss.xml" title="Kristijan Bakaric Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/personal-website/blog/atom.xml" title="Kristijan Bakaric Blog Atom Feed"><title data-react-helmet="true">Data Engineering Project - Pre-process data - Part 2 | Kristijan Bakaric</title><meta data-react-helmet="true" property="og:title" content="Data Engineering Project - Pre-process data - Part 2 | Kristijan Bakaric"><meta data-react-helmet="true" name="description" content="In this post I will briefly introduce Python functions and scripts that process the data from Kaggle, combine tweets and satellite images into a single file, acting as source data, and building a python program that will send requests to an Azure API endpoint."><meta data-react-helmet="true" property="og:description" content="In this post I will briefly introduce Python functions and scripts that process the data from Kaggle, combine tweets and satellite images into a single file, acting as source data, and building a python program that will send requests to an Azure API endpoint."><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:url" content="https://baky0905.github.io/personal-website/blog/2021/03/06/data-engineering-part2"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_tag" content="default"><link data-react-helmet="true" rel="shortcut icon" href="/personal-website/img/favicon.ico"><link data-react-helmet="true" rel="canonical" href="https://baky0905.github.io/personal-website/blog/2021/03/06/data-engineering-part2"><link data-react-helmet="true" rel="alternate" href="https://baky0905.github.io/personal-website/blog/2021/03/06/data-engineering-part2" hreflang="x-default"><link rel="stylesheet" href="/personal-website/assets/css/styles.d23e3c1a.css">
<link rel="preload" href="/personal-website/assets/js/styles.f0712210.js" as="script">
<link rel="preload" href="/personal-website/assets/js/runtime~main.5462b1ca.js" as="script">
<link rel="preload" href="/personal-website/assets/js/main.79c46ea4.js" as="script">
<link rel="preload" href="/personal-website/assets/js/1.7cb82093.js" as="script">
<link rel="preload" href="/personal-website/assets/js/2.fca674a5.js" as="script">
<link rel="preload" href="/personal-website/assets/js/3.bad86c3d.js" as="script">
<link rel="preload" href="/personal-website/assets/js/ccc49370.180471ef.js" as="script">
<link rel="preload" href="/personal-website/assets/js/7c459c90.378e2022.js" as="script">
<link rel="preload" href="/personal-website/assets/js/6f1ecc39.55c5485d.js" as="script">
</head>
<body>
<script>!function(){function e(e){document.documentElement.setAttribute("data-theme",e)}var t=function(){var e=null;try{e=localStorage.getItem("theme")}catch(e){}return e}();null!==t?e(t):window.matchMedia("(prefers-color-scheme: dark)").matches?e("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,e("light"))}()</script><div id="__docusaurus">
<nav aria-label="Skip navigation links"><button type="button" tabindex="0" class="skipToContent_1oUP">Skip to main content</button></nav><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><div aria-label="Navigation bar toggle" class="navbar__toggle" role="button" tabindex="0"><svg aria-label="Menu" width="30" height="30" viewBox="0 0 30 30" role="img" focusable="false"><title>Menu</title><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></div><a class="navbar__brand" href="/personal-website/"><img src="/personal-website/img/logo.png" alt="Site Logo" class="themedImage_1VuW themedImage--light_3UqQ navbar__logo"><img src="/personal-website/img/logo.png" alt="Site Logo" class="themedImage_1VuW themedImage--dark_hz6m navbar__logo"><strong class="navbar__title">KB</strong></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/personal-website/blog">Blog</a><a class="navbar__item navbar__link" href="/personal-website/blog/tags/projects">Projects</a><a class="navbar__item navbar__link" href="/personal-website/docs/bookmarks">THE Bookmarks</a><a class="navbar__item navbar__link" href="/personal-website/docs/bookmarks-norway">Awesome Norway</a></div><div class="navbar__items navbar__items--right"><a href="https://www.linkedin.com/in/kristijanb/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">LinkedIn</a><a href="https://github.com/baky0905" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub</a><a class="navbar__item navbar__link" href="/personal-website/docs/about/about-me">About Me</a></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div><div class="navbar-sidebar"><div class="navbar-sidebar__brand"><a class="navbar__brand" href="/personal-website/"><img src="/personal-website/img/logo.png" alt="Site Logo" class="themedImage_1VuW themedImage--light_3UqQ navbar__logo"><img src="/personal-website/img/logo.png" alt="Site Logo" class="themedImage_1VuW themedImage--dark_hz6m navbar__logo"><strong class="navbar__title">KB</strong></a></div><div class="navbar-sidebar__items"><div class="menu"><ul class="menu__list"><li class="menu__list-item"><a aria-current="page" class="menu__link navbar__link--active" href="/personal-website/blog">Blog</a></li><li class="menu__list-item"><a class="menu__link" href="/personal-website/blog/tags/projects">Projects</a></li><li class="menu__list-item"><a class="menu__link" href="/personal-website/docs/bookmarks">THE Bookmarks</a></li><li class="menu__list-item"><a class="menu__link" href="/personal-website/docs/bookmarks-norway">Awesome Norway</a></li><li class="menu__list-item"><a href="https://www.linkedin.com/in/kristijanb/" target="_blank" rel="noopener noreferrer" class="menu__link">LinkedIn</a></li><li class="menu__list-item"><a href="https://github.com/baky0905" target="_blank" rel="noopener noreferrer" class="menu__link">GitHub</a></li><li class="menu__list-item"><a class="menu__link" href="/personal-website/docs/about/about-me">About Me</a></li></ul></div></div></div></nav><div class="main-wrapper blog-wrapper"><div class="container margin-vert--lg"><div class="row"><div class="col col--2"><div class="sidebar_2ahu thin-scrollbar"><h3 class="sidebarItemTitle_2hhb">Recent posts</h3><ul class="sidebarItemList_2xAf"><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/personal-website/blog/2021/04/02/docusaurus">From Markdown to a Docusaurus Website via GitHub, gh Actions, and gh pages</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/personal-website/blog/2021/03/08/data-engineering-part4">Data Engineering Project - Azure Event Hubs, Function and Cosmos DB - Part 4</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/personal-website/blog/2021/03/07/data-engineering-part3">Data Engineering Project - Azure APIM, Azure Functions, Blob Storage - Part 3</a></li><li class="sidebarItem_2UVv"><a aria-current="page" class="sidebarItemLink_1RT6 sidebarItemLinkActive_12pM" href="/personal-website/blog/2021/03/06/data-engineering-part2">Data Engineering Project - Pre-process data - Part 2</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/personal-website/blog/2021/02/28/data-engineering-part1">Data Engineering Project - Intro - Part 1</a></li></ul></div></div><main class="col col--8"><article><header><h1 class="margin-bottom--sm blogPostTitle_GeHD">Data Engineering Project - Pre-process data - Part 2</h1><div class="margin-vert--md"><time datetime="2021-03-06T00:00:00.000Z" class="blogPostDate_fNvV">March 6, 2021  Â· 3 min read</time></div><div class="avatar margin-vert--md"><a class="avatar__photo-link avatar__photo" href="https://www.linkedin.com/in/kristijanb/" target="_blank" rel="noreferrer noopener"><img src="https://media-exp1.licdn.com/dms/image/C4E03AQF-5oI5fHJPjw/profile-displayphoto-shrink_800_800/0/1606336983715?e=1620259200&amp;v=beta&amp;t=VvBP6s8IMDUwKDfvj6B3c-gGmN3IfioALIAboXg_DGE" alt="Kristijan Bakaric"></a><div class="avatar__intro"><h4 class="avatar__name"><a href="https://www.linkedin.com/in/kristijanb/" target="_blank" rel="noreferrer noopener">Kristijan Bakaric</a></h4><small class="avatar__subtitle">Mr.</small></div></div></header><div class="markdown"><p><img src="https://images.unsplash.com/photo-1568438350562-2cae6d394ad0?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&amp;ixlib=rb-1.2.1&amp;auto=format&amp;fit=crop&amp;w=2100&amp;q=80"></p><blockquote><p>In this post I will briefly introduce Python functions and scripts that process the data from Kaggle, combine tweets and satellite images into a single file, acting as source data, and building a python program that will send requests to an Azure API endpoint. </p></blockquote><div class="admonition admonition-note alert alert--secondary"><div class="admonition-heading"><h5><span class="admonition-icon"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="16" viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</h5></div><div class="admonition-content"><p>Since there is no real relation between tweets and satellite images, for creating data pipelines in Azure, I have simulated and randomly assigned ids from images to tweets, and thus made an artificial relation.</p></div></div><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="introduction"></a>Introduction<a class="hash-link" href="#introduction" title="Direct link to heading">#</a></h2><p>I have briefly introduced the data sources in the <a href="/personal-website/blog/2021/02/28/data-engineering-part1">previous post</a> so I will skip the introduction of the datasets here. In figure 1, there is a high-level overview of what are the inputs and what are the outputs of the data processing, with the main aim of generating a JSON file that contains messages which I will send via HTTP requests to the Azure API Management API endpoint.</p><p><img src="/personal-website/assets/images/diagramme-811c652476759c0eec3404cc105941f0.png">
Figure 1: Diagramme of the data preparation process.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="python-scripts"></a>Python Scripts<a class="hash-link" href="#python-scripts" title="Direct link to heading">#</a></h2><p><a href="https://github.com/baky0905/hurricane-proc-send-data" target="_blank" rel="noopener noreferrer">Github Project</a> has four python files. They can each be tested locally on a sample dataset that is contained in the repository under <a href="https://github.com/baky0905/hurricane-proc-send-data/sample_data" target="_blank" rel="noopener noreferrer">./sample_data</a>, otherwise, navigate to original data sources and get the full datasets.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="preprocess_twitterpy"></a>preprocess_twitter.py<a class="hash-link" href="#preprocess_twitterpy" title="Direct link to heading">#</a></h3><blockquote><p>Script that processes original tweet messages.</p></blockquote><p><strong>Before processing:</strong></p><p><img src="/personal-website/assets/images/tweets_before-3da818a0f177de27559438d816859bd9.png"></p><p><strong>After processing:</strong></p><p><img src="/personal-website/assets/images/tweets_after-972ce9283e9840b1f0987242612f0b3d.png"></p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="preprocess_imagespy"></a>preprocess_images.py<a class="hash-link" href="#preprocess_imagespy" title="Direct link to heading">#</a></h3><blockquote><p>Script that processes file paths and names into an attribute table, together with a column that contains base64 encoded images.</p></blockquote><p><img src="/personal-website/assets/images/images_before-7b2cb8648c9cce93629c0d4747948b5f.png"></p><p><strong>After processing:</strong></p><p><img src="/personal-website/assets/images/images_after-205254e7464955858326f36aad7bcb45.png"></p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="merge_tweets_imagespy"></a>merge_tweets_images.py<a class="hash-link" href="#merge_tweets_imagespy" title="Direct link to heading">#</a></h3><blockquote><p>Script that merges processed tweet JSON and images into a single JSON file where images are base 64 encoded.</p></blockquote><p><strong>After merging processed tweets and images:</strong></p><p><img src="/personal-website/assets/images/tweets_images_merged-ba6dc7c59b4491a7a701c14ad210ff9a.png"></p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="push_tweetspy"></a><code>push_tweets.py</code><a class="hash-link" href="#push_tweetspy" title="Direct link to heading">#</a></h3><blockquote><blockquote><p>Script converted to Python CLI via <a href="https://google.github.io/python-fire/" target="_blank" rel="noopener noreferrer">Python Fire</a>. Script sends tweet records from JSON file as requests with a predefined header and schema. </p></blockquote></blockquote><p><strong>When in the CLI, type (number 5 is an argument for a number of tweets you would like to send towards REST API endpoint):</strong></p><div class="mdxCodeBlock_3lFL"><div class="codeBlockContent_hGly"><div tabindex="0" class="prism-code language-sh codeBlock_23N8 thin-scrollbar"><div class="codeBlockLines_39YC" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">python3 src/push_tweets.py send_tweets_to_rest_api 5</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o">Copy</button></div></div><p><strong>To send 5 tweet messages, one by one to a defined REST API endpoint in Azure.</strong></p><p><img src="/personal-website/assets/images/send_tweets-7a74d096152295668987ad5045edc412.png"></p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="in-the-next-post"></a>In the Next Post...<a class="hash-link" href="#in-the-next-post" title="Direct link to heading">#</a></h2><p>Now that we have the required data in the desired shape, format and content, we can proceed to design a data streaming pipeline in Azure.</p><p>The goal will be to create the first part of the data streaming pipeline which consists of an API gateway accepting API calls and routing them to the Azure function that processes the data and (initially) stores them to Azure Blob Storage.</p><p>In the next post, I will introduce and create the following Azure Services:</p><ul><li><p><a href="https://docs.microsoft.com/en-us/azure/api-management/api-management-key-concepts" target="_blank" rel="noopener noreferrer">Azure API Management</a></p></li><li><p><a href="https://docs.microsoft.com/en-us/azure/azure-functions/functions-overview" target="_blank" rel="noopener noreferrer">Azure Functions</a></p></li><li><p><a href="https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blobs-introduction" target="_blank" rel="noopener noreferrer">Azure Blob Storage</a> </p></li></ul></div><footer class="row margin-vert--lg"><div class="col"><strong>Tags:</strong><a class="margin-horiz--sm" href="/personal-website/blog/tags/dataengineering">dataengineering</a><a class="margin-horiz--sm" href="/personal-website/blog/tags/projects">projects</a><a class="margin-horiz--sm" href="/personal-website/blog/tags/azure">azure</a><a class="margin-horiz--sm" href="/personal-website/blog/tags/python">python</a></div></footer></article><div></div><div class="margin-vert--xl"><nav class="pagination-nav" aria-label="Blog post page navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/personal-website/blog/2021/03/07/data-engineering-part3"><div class="pagination-nav__sublabel">Newer Post</div><div class="pagination-nav__label">Â« Data Engineering Project - Azure APIM, Azure Functions, Blob Storage - Part 3</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/personal-website/blog/2021/02/28/data-engineering-part1"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">Data Engineering Project - Intro - Part 1 Â»</div></a></div></nav></div></main><div class="col col--2"><div class="tableOfContents_35-E thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#introduction" class="table-of-contents__link">Introduction</a></li><li><a href="#python-scripts" class="table-of-contents__link">Python Scripts</a><ul><li><a href="#preprocess_twitterpy" class="table-of-contents__link">preprocess_twitter.py</a></li><li><a href="#preprocess_imagespy" class="table-of-contents__link">preprocess_images.py</a></li><li><a href="#merge_tweets_imagespy" class="table-of-contents__link">merge_tweets_images.py</a></li><li><a href="#push_tweetspy" class="table-of-contents__link"><code>push_tweets.py</code></a></li></ul></li><li><a href="#in-the-next-post" class="table-of-contents__link">In the Next Post...</a></li></ul></div></div></div></div></div><footer class="footer"><div class="container"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2021 Kristijan Bakaric, Built with Docusaurus.</div></div></div></footer></div>
<script src="/personal-website/assets/js/styles.f0712210.js"></script>
<script src="/personal-website/assets/js/runtime~main.5462b1ca.js"></script>
<script src="/personal-website/assets/js/main.79c46ea4.js"></script>
<script src="/personal-website/assets/js/1.7cb82093.js"></script>
<script src="/personal-website/assets/js/2.fca674a5.js"></script>
<script src="/personal-website/assets/js/3.bad86c3d.js"></script>
<script src="/personal-website/assets/js/ccc49370.180471ef.js"></script>
<script src="/personal-website/assets/js/7c459c90.378e2022.js"></script>
<script src="/personal-website/assets/js/6f1ecc39.55c5485d.js"></script>
</body>
</html>